export const exerciseNotebook = {
  "c√©lulas": [
    {
      "tipo_celda": "markdown",
      "fuente": [
        "# El Proceso Completo del An√°lisis de Datos\n",
        "El an√°lisis de datos moderno se basa en la capacidad de convertir informaci√≥n cruda en conocimiento √∫til. Para lograrlo, se emplea un proceso estructurado que comienza con la extracci√≥n, transformaci√≥n y carga (ETL) de los datos, seguido de su limpieza y normalizaci√≥n, y culmina con la aplicaci√≥n de modelos de Machine Learning que permiten clasificar, agrupar o predecir comportamientos.\n\n",
        "El objetivo es obtener datos reales, confiables y estructurados que puedan alimentar herramientas como Power BI, Tableau o sistemas inteligentes desarrollados en Python."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## Proceso ETL (Extracci√≥n, Transformaci√≥n y Carga)\n",
        "La extracci√≥n es el primer paso del proceso ETL (Extract, Transform, Load) y consiste en obtener datos desde m√∫ltiples fuentes ‚Äîestructuradas o no estructuradas‚Äî para centralizarlos en un √∫nico entorno de an√°lisis.\n\n",
        "En esta fase, el objetivo es recolectar toda la informaci√≥n relevante sin alterar su contenido original, garantizando la integridad de los datos."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### üß© Fuentes m√°s comunes de extracci√≥n\n",
        "**Archivos CSV y de texto plano:**\n",
        "Son los formatos m√°s ligeros y ampliamente utilizados para el intercambio de datos tabulares."
      ]
    },
    {
      "tipo_celda": "c√≥digo",
      "fuente": [
        "import pandas as pd\n",
        "datos_csv = pd.read_csv(\"datos.csv\", encoding=\"utf-8\")"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "Estos archivos sirven luego como base estandarizada para integrar datos de otras fuentes.\n\n",
        "**Archivos Excel (una o varias hojas):**\n",
        "Es com√∫n que una organizaci√≥n maneje m√∫ltiples hojas con informaci√≥n distinta (por ejemplo: ventas, clientes, inventario).\n",
        "Cada hoja puede extraerse de manera independiente o consolidarse en un solo DataFrame:"
      ]
    },
    {
      "tipo_celda": "c√≥digo",
      "fuente": [
        "archivo_excel = pd.ExcelFile(\"datos_empresariales.xlsx\")\n",
        "hoja1 = pd.read_excel(archivo_excel, \"Ventas\")\n",
        "hoja2 = pd.read_excel(archivo_excel, \"Clientes\")\n",
        "hoja3 = pd.read_excel(archivo_excel, \"Inventario\")\n",
        "\n",
        "# Combinar todas las hojas\n",
        "datos_excel = pd.concat([hoja1, hoja2, hoja3], ignore_index=True)"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "Esta pr√°ctica permite unificar la informaci√≥n dispersa antes de continuar con la transformaci√≥n.\n\n",
        "**Archivos JSON (estructurados en jerarqu√≠as):**\n",
        "Comunes en servicios web y APIs. Se convierten f√°cilmente en estructuras tabulares:"
      ]
    },
    {
      "tipo_celda": "c√≥digo",
      "fuente": [
        "datos_json = pd.read_json(\"api_response.json\")"
      ]
    },
    {
        "tipo_celda": "markdown",
        "fuente": [
            "**Bases de datos SQL y MySQL (y sus derivados como PostgreSQL, MariaDB, SQLite, etc.):**\n",
            "Permiten acceder a informaci√≥n almacenada de manera relacional.\n",
            "Python, mediante `sqlalchemy` o `mysql.connector`, puede conectarse directamente y ejecutar consultas SQL:"
        ]
    },
    {
        "tipo_celda": "c√≥digo",
        "fuente": [
            "import mysql.connector\n",
            "import pandas as pd\n\n",
            "conexion = mysql.connector.connect(\n",
            "    host=\"localhost\",\n",
            "    user=\"usuario\",\n",
            "    password=\"contrase√±a\",\n",
            "    database=\"nombre_bd\"\n",
            ")\n\n",
            "query = \"SELECT * FROM ventas;\"\n",
            "datos_sql = pd.read_sql(query, conexion)\n",
            "conexion.close()"
        ]
    },
    {
        "tipo_celda": "markdown",
        "fuente": [
            "Esta conexi√≥n se adapta f√°cilmente a otros sistemas como PostgreSQL, SQL Server o SQLite modificando el conector y la cadena de conexi√≥n.\n\n",
            "**APIs (interfaces de servicios externos):**\n",
            "Se utilizan para extraer datos din√°micos o actualizados en tiempo real (por ejemplo, precios, clima, redes sociales).\n",
            "Con la librer√≠a `requests`:"
        ]
    },
    {
        "tipo_celda": "c√≥digo",
        "fuente": [
            "import requests\n\n",
            "respuesta = requests.get(\"https://api.ejemplo.com/datos\")\n",
            "datos_api = pd.json_normalize(respuesta.json())"
        ]
    },
    {
        "tipo_celda": "markdown",
        "fuente": [
            "### Conversi√≥n y consolidaci√≥n\n",
            "Una vez extra√≠dos los datos desde Excel, SQL, APIs o JSON, es buena pr√°ctica convertirlos a un formato unificado (CSV) antes de continuar con la fase de transformaci√≥n.\n",
            "Esto garantiza compatibilidad con herramientas de an√°lisis (Power BI, Tableau, etc.) y facilita la trazabilidad del proceso ETL."
        ]
    },
    {
        "tipo_celda": "c√≥digo",
        "fuente": [
            "# Guardar los datos consolidados en un CSV limpio\n",
            "datos_consolidados = pd.concat([datos_csv, datos_excel, datos_sql, datos_api], ignore_index=True)\n",
            "datos_consolidados.to_csv(\"datos_unificados.csv\", index=False, encoding=\"utf-8\")"
        ]
    },
    {
        "tipo_celda": "markdown",
        "fuente": [
            "Con esto, el analista dispone de un solo archivo `datos_unificados.csv` listo para iniciar la transformaci√≥n y limpieza, asegurando que toda la informaci√≥n (de hojas Excel, bases SQL y APIs) est√© integrada en un formato est√°ndar."
        ]
    },
    {
        "tipo_celda": "markdown",
        "fuente": [
            "## 3. Limpieza y transformaci√≥n de datos\n",
            "Esta etapa busca asegurar la calidad y consistencia. Las tareas principales incluyen:\n\n",
            "| Tarea | Objetivo | Ejemplo |\n",
            "|---|---|---|\n",
            "| Eliminaci√≥n de nulos | Evitar errores en modelos | `df.dropna()` |\n",
            "| Detecci√≥n de outliers | Evitar distorsi√≥n estad√≠stica | Boxplot, z-score |\n",
            "| Codificaci√≥n categ√≥rica| Transformar texto en n√∫meros | `pd.get_dummies(df)` |\n",
            "| Estandarizaci√≥n de formato | Uniformar valores | Convertir a may√∫sculas, fechas uniformes |"
        ]
    },
    {
        "tipo_celda": "markdown",
        "fuente": [
            "## üîπ 4. Normalizaci√≥n, afinaci√≥n y aceleraci√≥n\n",
            "### 4.1. Normalizaci√≥n\n",
            "Normalizar es ajustar los valores num√©ricos a una misma escala, lo cual mejora la precisi√≥n de los modelos.\n\n",
            "**Min-Max Scaling:** lleva los datos entre 0 y 1.\n",
            "`X' = (X - X_min) / (X_max - X_min)`\n\n",
            "**Z-score (estandarizaci√≥n):**\n",
            "`X' = (X - Œº) / œÉ`\n",
            "donde `Œº` es la media y `œÉ` la desviaci√≥n est√°ndar."
        ]
    },
    {
        "tipo_celda": "c√≥digo",
        "fuente": [
            "from sklearn.preprocessing import StandardScaler\n",
            "scaler = StandardScaler()\n",
            "df_scaled = scaler.fit_transform(df[['edad', 'ingresos']])"
        ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### 4.2. Afinaci√≥n\n",
        "La afinaci√≥n consiste en optimizar los par√°metros del modelo para obtener mejor rendimiento. En Machine Learning, esto se logra con t√©cnicas como:\n",
        "- GridSearchCV (b√∫squeda exhaustiva)\n",
        "- RandomSearchCV (b√∫squeda aleatoria)\n",
        "- Cross Validation\n"
      ]
    },
    {
      "tipo_celda": "c√≥digo",
      "fuente": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "// Sirve para ajustar variables como n√∫mero de clusters (en K-Means) o par√°metros de suavizado (en Naive Bayes)."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### 4.3. Aceleraci√≥n\n",
        "Busca reducir tiempos de procesamiento mediante:\n",
        "- Procesamiento paralelo (joblib, dask, pyspark).\n",
        "- Reducci√≥n de dimensionalidad (PCA).\n",
        "- Filtrado de datos irrelevantes antes del modelado."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## üîπ 5. Machine Learning\n",
        "El aprendizaje autom√°tico permite que los sistemas aprendan patrones de los datos. Se divide en tres grandes tipos:\n\n",
        "| Tipo | Caracter√≠stica | Ejemplo |\n",
        "|---|---|---|\n",
        "| Supervisado | Usa datos etiquetados (con respuesta) | Clasificaci√≥n, regresi√≥n |\n",
        "| No supervisado | Agrupa sin etiquetas previas | Clustering, K-Means |\n",
        "| Por refuerzo | Aprende por prueba y error | Robots, videojuegos, trading |"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## üîπ 6. Algoritmo Naive Bayes\n",
        "### 6.1. Concepto\n",
        "Basado en el Teorema de Bayes, este m√©todo calcula la probabilidad de que una observaci√≥n pertenezca a una clase, asumiendo independencia entre variables.\n",
        "`P(A|B) = (P(B|A) * P(A)) / P(B)`\n\n",
        "En clasificaci√≥n:\n",
        "`P(Clase|Datos) = (P(Datos|Clase) * P(Clase)) / P(Datos)`"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### 6.2. Ejemplo pr√°ctico ‚Äî Clasificaci√≥n de correos ‚ÄúSpam‚Äù o ‚ÄúNo Spam‚Äù\n",
        "Tenemos 5 correos:\n",
        "- 3 Spam ‚Üí `P(Spam) = 0.6`\n",
        "- 2 No Spam ‚Üí `P(NoSpam) = 0.4`\n\n",
        "**Probabilidades condicionales:**\n\n",
        "| Palabra | P(x|Spam) | P(x|NoSpam) |\n",
        "|---|---|---|\n",
        "| Gratis | 0.67 | 0 |\n",
        "| Oferta | 0.67 | 0.5 |\n",
        "| Urgente | 0.67 | 0.5 |\n\n",
        "**C√°lculo:**\n",
        "`P(Spam|Gratis,Oferta,Urgente) = 0.6 * 0.67 * 0.67 * 0.67 = 0.179`\n",
        "`P(NoSpam|Gratis,Oferta,Urgente) = 0.4 * 0 * 0.5 * 0.5 = 0`\n\n",
        "‚úÖ **Conclusi√≥n:** El correo se clasifica como Spam."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### 6.3. Implementaci√≥n b√°sica en Python"
      ]
    },
    {
      "tipo_celda": "c√≥digo",
      "fuente": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n\n",
        "textos = [\"Oferta urgente gratis\", \"Reuni√≥n de trabajo\", \"Promoci√≥n oferta gratis urgente\"]\n",
        "y = [1, 0, 1]  # 1 = Spam, 0 = NoSpam\n\n",
        "vectorizador = CountVectorizer()\n",
        "X = vectorizador.fit_transform(textos)\n\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(X, y)\n\n",
        "nuevo = vectorizador.transform([\"Oferta gratis\"])\n",
        "print(modelo.predict(nuevo))  # Resultado: Spam (1)"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## üîπ 7. Algoritmo K-Means (Agrupamiento)\n",
        "### 7.1. Concepto\n",
        "K-Means es un m√©todo no supervisado que agrupa datos similares en K grupos (clusters). Su objetivo es minimizar la distancia entre los puntos y el centroide de su grupo.\n\n",
        "`J = Œ£ (de i=1 a K) Œ£ (para xj en Ci) ||xj - Œºi||¬≤`"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### 7.2. Proceso\n",
        "1. Elegir **K** (n√∫mero de clusters).\n",
        "2. Inicializar centroides aleatorios.\n",
        "3. Asignar cada punto al cluster m√°s cercano (seg√∫n distancia euclidiana).\n",
        "4. Recalcular centroides.\n",
        "5. Repetir hasta converger."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "### 7.3. Ejemplo en Python"
      ]
    },
    {
      "tipo_celda": "c√≥digo",
      "fuente": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n\n",
        "X = [[1,2],[1,4],[1,0],[10,2],[10,4],[10,0]]\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n\n",
        "plt.scatter([x[0] for x in X], [x[1] for x in X], c=kmeans.labels_)\n",
        "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], color='red', marker='X')\n",
        "plt.show()"
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "Este algoritmo agrupa datos similares (por ejemplo, clientes con comportamientos parecidos)."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## üîπ 8. Diferencias entre Naive Bayes y K-Means\n\n",
        "| Aspecto | Naive Bayes | K-Means |\n",
        "|---|---|---|\n",
        "| Tipo | Supervisado | No supervisado |\n",
        "| Objetivo | Clasificar | Agrupar |\n",
        "| Entrada | Datos con etiquetas | Datos sin etiquetas |\n",
        "| Fundamento | Probabilidad (Teorema de Bayes) | Distancias (Euclidianas) |\n",
        "| Resultado | Probabilidad de clase | Clusters definidos |\n",
        "| Uso com√∫n | Detecci√≥n de spam, an√°lisis de texto | Segmentaci√≥n de clientes, patrones |\n\n",
        "Ambos son complementarios: Bayes predice clases, mientras K-Means descubre patrones ocultos."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## Interpretabilidad y sesgos\n",
        "Un punto crucial del an√°lisis de datos es entender c√≥mo el modelo toma decisiones y qu√© sesgos pueden existir. Por ejemplo:\n\n",
        "- En **Naive Bayes**, una palabra con probabilidad cero puede eliminar completamente una clase (por eso se usa suavizado de Laplace).\n",
        "- En **K-Means**, la elecci√≥n del n√∫mero de clusters puede cambiar totalmente los resultados.\n\n",
        "Por ello, se recomienda:\n",
        "- Validar con m√©tricas objetivas.\n",
        "- Aplicar visualizaci√≥n de resultados.\n",
        "- Evaluar impactos √©ticos o de sesgo en datos sensibles."
      ]
    },
    {
      "tipo_celda": "markdown",
      "fuente": [
        "## üîπ 11. Conclusi√≥n general\n",
        "El proceso completo ‚Äîdesde la extracci√≥n y limpieza de datos (ETL) hasta la aplicaci√≥n de modelos de Machine Learning (Naive Bayes y K-Means)‚Äî constituye la base de la anal√≠tica moderna orientada a la toma de decisiones.\n\n",
        "Cada etapa cumple un papel espec√≠fico:\n",
        "- **ETL:** Garantiza que los datos sean v√°lidos y coherentes.\n",
        "- **Normalizaci√≥n:** Mejora la precisi√≥n de los modelos.\n",
        "- **Naive Bayes:** Clasifica seg√∫n evidencia probabil√≠stica.\n",
        "- **K-Means:** Descubre patrones ocultos sin etiquetas.\n\n",
        "Ambos algoritmos, junto con una correcta preparaci√≥n y afinaci√≥n de datos, permiten crear sistemas inteligentes capaces de analizar informaci√≥n real, detectar comportamientos y generar visualizaciones de alto valor estrat√©gico."
      ]
    }
  ],
  "metadatos": {
    "colaboraci√≥n": {
      "procedencia": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
